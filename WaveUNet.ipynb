{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7d9a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from scipy import signal\n",
    "import librosa\n",
    "import time\n",
    "from scipy.io import wavfile\n",
    "import glob\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ff33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioMix(Dataset):\n",
    "    def __init__(self, folder, n_examples, clip_len, sr=16000):\n",
    "        \"\"\"\n",
    "        Setup data of audio mixtures\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        folder: string\n",
    "            Folder containing tracks\n",
    "        n_examples: int\n",
    "            Number of examples to create in a batch\n",
    "        clip_len: float\n",
    "            Length of a clip, in samples\n",
    "        sr: int\n",
    "            Sample rate\n",
    "        \"\"\"\n",
    "        self.n_examples = n_examples\n",
    "        self.clip_len = clip_len\n",
    "        self.sr = sr\n",
    "        files = glob.glob(\"{}/*.mp3\".format(folder))\n",
    "        self.x = []\n",
    "        for f in files:\n",
    "            xi, _ = librosa.load(f, sr=sr)\n",
    "            self.x.append(xi)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_examples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        S is \"source\", M is \"mixture\"\n",
    "        \"\"\"\n",
    "        n_clips = len(self.x)\n",
    "        mix = np.random.rand(n_clips)\n",
    "        mix = mix/np.sum(mix)\n",
    "        N = len(self.x[0])\n",
    "        i1 = np.random.randint(N-self.clip_len)\n",
    "        S = [np.array(mi*xi[i1:i1+self.clip_len], dtype=np.float32) for mi, xi in zip(mix, self.x)]\n",
    "        M = np.zeros_like(S[0]) # Mixture audio\n",
    "        for xi in S:\n",
    "            M += xi\n",
    "        S = torch.from_numpy(np.array(S, dtype=np.float32))\n",
    "        M = torch.from_numpy(M[None, :])\n",
    "        return M, S\n",
    "        \n",
    "data = AudioMix(\"Aha\", 2000, 16384)\n",
    "M, S = data[0]\n",
    "print(\"S.shape\", S.shape)\n",
    "print(\"M.shape\", M.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b746a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(data, shuffle=True, batch_size=16)\n",
    "M, S = next(iter(loader))\n",
    "print(S.shape)\n",
    "conv = nn.Conv1d(1, 24, 15, stride=1, padding=7, bias=False)\n",
    "Mc = conv(M)\n",
    "print(Mc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1af773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decimate(nn.Module):\n",
    "    \"\"\"\n",
    "    Decimate by a factor of fac across the time axis (axis=1)\n",
    "    \"\"\"\n",
    "    def __init__(self, fac):\n",
    "        super(Decimate, self).__init__()\n",
    "        self.fac = fac\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X[:, :, 0::self.fac]\n",
    "\n",
    "class WaveUNet(nn.Module):\n",
    "    def __init__(self, C, L=12, Fc=24, fd=15, fu=5):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        C: int\n",
    "            Number of mixture components\n",
    "        L: int\n",
    "            Number of layers\n",
    "        Fc: int\n",
    "            Number of extra filters per layer\n",
    "        fd: int\n",
    "            Kernel size for downsampling\n",
    "        fu: int\n",
    "            Kernel size for upsampling\n",
    "        \"\"\"\n",
    "        super(WaveUNet, self).__init__()\n",
    "        self.C = C\n",
    "        \n",
    "        ## Step 1: Create the convolutional down layers\n",
    "        \n",
    "        \n",
    "        ## Step 2: Create the convolutional up layers\n",
    "        \n",
    "        \n",
    "        ## Step 3: Create the last layer\n",
    "        \n",
    "    \n",
    "    def forward(self, M, verbose=False):\n",
    "        relu = nn.LeakyReLU()\n",
    "        downsample = Decimate(2)\n",
    "        upsample = nn.Upsample(scale_factor=2, mode='linear')\n",
    "        \n",
    "    \n",
    "model = WaveUNet(len(data.x))\n",
    "S_est = model(M)\n",
    "print(S_est.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f65ec7",
   "metadata": {},
   "source": [
    "# Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead198a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use the GPU\n",
    "device = 'cuda'\n",
    "\n",
    "def get_data(path, sr=16000):\n",
    "    # Test data\n",
    "    M_test, sr = librosa.load(path, sr=sr)\n",
    "    # Round down to nearest power of 2\n",
    "    N = 2**int(np.floor(np.log2(M_test.size)))\n",
    "    M_test = M_test[0:N]\n",
    "    M_test = np.array(M_test[None, None, :], dtype=np.float32)\n",
    "    M_test = torch.from_numpy(M_test).to(device)\n",
    "    return M_test\n",
    "\n",
    "#M_test_real = get_data(\"TakeOnMe.mp3\")\n",
    "M_test = get_data(\"TakeOnMeMidiMix.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60701039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = WaveUNet(len(data.x), L=11)\n",
    "model = model.to(device)\n",
    "\n",
    "## Step 3: Setup the loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "n_epochs = 200 # Each \"epoch\" is a loop through the entire dataset\n",
    "# and we use this to update the parameters\n",
    "train_losses = []\n",
    "\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.9)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    loader = DataLoader(data, batch_size=16, shuffle=True)\n",
    "    train_loss = 0\n",
    "    for M, S in loader: # Go through each mini batch\n",
    "        # Move inputs/outputs to GPU\n",
    "        M = M.to(device)\n",
    "        S = S.to(device)\n",
    "        # Reset the optimizer's gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Run the sequential model on all inputs\n",
    "        S_est = model(M)\n",
    "        # Compute the loss function comparing S_est to S\n",
    "        loss = torch.sum((S_est - S)**2)\n",
    "        # Compute the gradients of the loss function with respect\n",
    "        # to all of the parameters of the model\n",
    "        loss.backward()\n",
    "        # Update the parameters based on the gradient and\n",
    "        # the optimization scheme\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    print(\"Epoch {}, loss {:.3f}\".format(epoch, train_loss))\n",
    "    train_losses.append(train_loss)\n",
    "    scheduler.step()\n",
    "    \n",
    "    S_test = model(M_test).detach().cpu().numpy()\n",
    "    for i in range(S_test.shape[1]):\n",
    "        s = S_test[0, i, :]\n",
    "        s = np.array(s*32768/np.max(np.abs(s)), dtype=np.int16)\n",
    "        wavfile.write(\"track{}.wav\".format(i), 16000, s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e132e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a68eed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
